# SQL Compiler - Reorganized Architecture

A modular SQL compiler frontend implemented with ANTLR and Python, featuring lexical analysis, syntax parsing, AST construction, and semantic analysis.

## ğŸ“ Project Structure
```
sql_compiler/
â”œâ”€â”€ grammars/              # ANTLR grammar files
â”‚   â”œâ”€â”€ BaseLexer.g4
â”‚   â”œâ”€â”€ ExpressionParser.g4
â”‚   â”œâ”€â”€ StatementParser.g4
â”‚   â””â”€â”€ SQLParser.g4
â”‚
â”œâ”€â”€ lexers/                # Lexical analysis
â”‚   â”œâ”€â”€ base_lexer.py
â”‚   â””â”€â”€ token_classifier.py
â”‚
â”‚
â”œâ”€â”€ ast/                   # AST node definitions
â”‚   â”œâ”€â”€ base_nodes.py
â”‚   â”œâ”€â”€ expression_nodes.py
â”‚   â”œâ”€â”€ statement_nodes.py
â”‚   â””â”€â”€ condition_nodes.py
â”‚
â”œâ”€â”€ builders/              # AST construction
â”‚   â”œâ”€â”€ expression_builder.py
â”‚   â”œâ”€â”€ statement_builder.py
â”‚   â”œâ”€â”€ condition_builder.py
â”‚   â””â”€â”€ ast_builder.py
â”‚
â”œâ”€â”€ semantic/              # Semantic analysis
â”‚   â”œâ”€â”€ symbol_table.py
â”‚   â””â”€â”€ semantic_analyzer.py
â”‚
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ error_handler.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ main.py               # Main entry point
â”œâ”€â”€ testLexer.py          # Lexer testing
â”œâ”€â”€ token_viewer.py       # Token visualization
â”œâ”€â”€ sqlInput.txt          # Sample SQL input
â”œâ”€â”€ testing.sql           # Test SQL file
â””â”€â”€ README.md
```

## âœ¨ Features

- **Modular Architecture**: Clean separation of concerns
- **Lexical Analysis**: Token generation and classification
- **Syntax Parsing**: ANTLR-based parser with visitor pattern
- **AST Construction**: Hierarchical AST representation
- **Semantic Analysis**: Symbol table, type checking, validation
- **Error Handling**: Comprehensive error reporting with colors
- **Visualization**: Browser-based AST and token visualization

## ğŸš€ Installation

### Prerequisites

- Python 3.8+
- Java 8+ (for ANTLR code generation)
- ANTLR 4.13.2

### Setup

1. Install Python dependencies:
```bash
pip install antlr4-python3-runtime
```

2. Generate parser and lexer (if needed):
```bash
# Using existing grammars
antlr4 -Dlanguage=Python3 -visitor grammars/BaseLexer.g4
antlr4 -Dlanguage=Python3 -visitor grammars/ExpressionParser.g4
antlr4 -Dlanguage=Python3 -visitor grammars/StatementParser.g4
antlr4 -Dlanguage=Python3 -visitor grammars/SQLParser.g4
```

## ğŸ“– Usage

### Run Main Compiler
```bash
python main.py
```

This will:
1. Perform lexical analysis
2. Parse the SQL
3. Build the AST
4. Run semantic analysis
5. Open AST visualization in browser

### Run Lexer Tests
```bash
python testLexer.py
```

Features:
- Colored token output
- Syntax validation
- Semantic analysis
- Detailed reports

### Run Token Viewer (GUI)
```bash
python token_viewer.py
```

Opens a Tkinter GUI showing:
- Token table
- Error and warning dialogs
- Token statistics

## ğŸ—ï¸ Architecture

### 1. Lexical Analysis (`lexers/`)

- **BaseLexer**: Wrapper for ANTLR lexer
- **TokenClassifier**: Token validation and classification

### 2. Parsing (`grammers/`)

Generated ANTLR parsers:
- Expression parser
- Statement parser
- Main SQL parser

### 3. AST Construction (`builders/`)

- **ExpressionBuilder**: Builds expression nodes
- **ConditionBuilder**: Builds condition nodes
- **StatementBuilder**: Builds statement nodes
- **AstBuilder**: Main builder coordinator

### 4. AST Nodes (`ast/`)

- **base_nodes**: Base classes
- **expression_nodes**: Expression AST nodes
- **statement_nodes**: Statement AST nodes
- **condition_nodes**: Condition AST nodes

### 5. Semantic Analysis (`semantic/`)

- **SymbolTable**: Manages tables, columns, variables
- **SemanticAnalyzer**: Validates semantics

### 6. Utilities (`utils/`)

- **ErrorHandler**: Centralized error management
- **Logger**: Logging functionality

## ğŸ¨ Features in Detail

### Lexical Analysis
```python
from lexers.base_lexer import BaseLexer
from lexers.token_classifier import TokenClassifier

lexer = BaseLexer(sql_code)
tokens = lexer.get_token_list()

classifier = TokenClassifier()
classifier.validate_syntax(tokens, sql_code)
```

### AST Construction
```python
from builders.ast_builder import AstBuilder

builder = AstBuilder()
ast = builder.visit(parse_tree)
```

### Semantic Analysis
```python
from semantic.semantic_analyzer import SemanticAnalyzer

analyzer = SemanticAnalyzer()
errors, warnings = analyzer.analyze_tokens(tokens)
report = analyzer.generate_report()
```

### Error Handling
```python
from utils.error_handler import ErrorHandler

handler = ErrorHandler()
handler.add_error(line, col, message, "SEMANTIC")
handler.print_all()
```

## ğŸ“Š Supported SQL Features

- âœ… CREATE TABLE
- âœ… ALTER TABLE (ADD/DROP)
- âœ… SELECT (with WHERE, ORDER BY, FROM)
- âœ… INSERT (VALUES, SELECT, EXEC)
- âœ… UPDATE (with WHERE)
- âœ… DELETE (with WHERE)
- âœ… DECLARE variables
- âœ… SET variables
- âœ… IF statements
- âœ… BEGIN...END blocks
- âœ… TRY...CATCH blocks
- âœ… EXEC stored procedures
- âœ… CASE expressions
- âœ… Complex conditions (AND, OR, IN, IS NULL)

## ğŸ§ª Testing

### Test Files

- `sqlInput.txt`: Main test SQL file
- `testing.sql`: Alternative test file

### Run Tests
```bash
# Test lexer
python testLexer.py

# Test full compiler
python main.py

# GUI token viewer
python token_viewer.py
```

## ğŸ“ Example
```sql
CREATE TABLE [dbo].[Customers](
    [CustomerID] [int] NOT NULL,
    [FirstName] [nvarchar](50) NOT NULL,
    [LastName] [nvarchar](50) NULL
)

SELECT CustomerID, FirstName, LastName
FROM Customers
WHERE CustomerID > 100
ORDER BY LastName ASC;
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is for educational purposes.

## ğŸ”— Resources

- [ANTLR Documentation](https://www.antlr.org/)
- [Python dataclasses](https://docs.python.org/3/library/dataclasses.html)

SQL Server Documentation