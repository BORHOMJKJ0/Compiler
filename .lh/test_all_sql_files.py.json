{
    "sourceFile": "test_all_sql_files.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 11,
            "patches": [
                {
                    "date": 1769012520768,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1769012544009,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,20 +4,21 @@\n Tests: train.sql, train2.sql, testing.sql, full_sql_test.sql\n \"\"\"\n \n import json\n+import sys\n from pathlib import Path\n-from Ast.ast_builder import AstBuilder\n-from utils.logger import Logger\n+from builders.ast_builder import AstBuilder\n \n+\n def count_nulls_in_ast(node, null_fields=None):\n     \"\"\"Recursively count null values in AST, tracking which fields are null.\"\"\"\n     if null_fields is None:\n         null_fields = {}\n-    \n+\n     if node is None:\n         return null_fields\n-    \n+\n     if isinstance(node, dict):\n         for key, value in node.items():\n             if value is None:\n                 null_fields[key] = null_fields.get(key, 0) + 1\n@@ -25,104 +26,115 @@\n                 count_nulls_in_ast(value, null_fields)\n     elif isinstance(node, list):\n         for item in node:\n             count_nulls_in_ast(item, null_fields)\n-    \n+\n     return null_fields\n \n+\n def test_sql_file(filepath):\n     \"\"\"Test a single SQL file and report results.\"\"\"\n     print(f\"\\n{'='*70}\")\n     print(f\"Testing: {Path(filepath).name}\")\n     print('='*70)\n-    \n+\n     try:\n         with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n             sql_content = f.read()\n-        \n+\n         print(f\"File size: {len(sql_content)} characters\")\n-        \n+\n         builder = AstBuilder()\n         ast = builder.build(sql_content)\n-        \n+\n         if not ast:\n             print(\"❌ FAILED: No AST generated\")\n             return False\n-        \n+\n         # Convert to JSON for analysis\n         if isinstance(ast, list):\n-            json_output = json.dumps([stmt.__dict__ if hasattr(stmt, '__dict__') else stmt for stmt in ast], indent=2, default=str)\n+            json_output = json.dumps([stmt.__dict__ if hasattr(\n+                stmt, '__dict__') else stmt for stmt in ast], indent=2, default=str)\n             statement_count = len(ast)\n         else:\n-            json_output = json.dumps(ast.__dict__ if hasattr(ast, '__dict__') else ast, indent=2, default=str)\n+            json_output = json.dumps(ast.__dict__ if hasattr(\n+                ast, '__dict__') else ast, indent=2, default=str)\n             statement_count = 1\n-        \n+\n         print(f\"✓ Parsed {statement_count} statement(s)\")\n         print(f\"AST Output length: {len(json_output)} characters\")\n-        \n+\n         # Count null values\n         ast_dict = json.loads(json_output)\n         null_fields = count_nulls_in_ast(ast_dict)\n-        \n+\n         # Critical fields that should not be null\n-        critical_fields = {'selectList', 'expression', 'fromClause', 'whereClause', 'orderByClause', 'column_name', 'tableName'}\n-        \n-        critical_nulls = {k: v for k, v in null_fields.items() if k in critical_fields}\n-        \n+        critical_fields = {'selectList', 'expression', 'fromClause',\n+                           'whereClause', 'orderByClause', 'column_name', 'tableName'}\n+\n+        critical_nulls = {k: v for k,\n+                          v in null_fields.items() if k in critical_fields}\n+\n         if critical_nulls:\n-            print(f\"⚠️  WARNING: Found nulls in critical fields: {critical_nulls}\")\n+            print(\n+                f\"⚠️  WARNING: Found nulls in critical fields: {critical_nulls}\")\n             return False\n         else:\n             print(\"✓ No nulls in critical fields\")\n-        \n+\n         # Show first statement sample\n         if isinstance(ast_dict, list) and ast_dict:\n             first_stmt = ast_dict[0]\n-            print(f\"\\nFirst statement type: {first_stmt.get('__class__', 'unknown')}\")\n+            print(\n+                f\"\\nFirst statement type: {first_stmt.get('__class__', 'unknown')}\")\n             if 'selectList' in first_stmt and first_stmt['selectList']:\n                 print(f\"  - selectList items: {len(first_stmt['selectList'])}\")\n                 first_item = first_stmt['selectList'][0]\n-                print(f\"    - First item expression: {type(first_item.get('expression'))}\")\n+                print(\n+                    f\"    - First item expression: {type(first_item.get('expression'))}\")\n                 if isinstance(first_item.get('expression'), dict):\n                     expr = first_item['expression']\n                     print(f\"      - column_name: {expr.get('column_name')}\")\n                     print(f\"      - table_name: {expr.get('table_name')}\")\n-        \n+\n         return True\n-    \n+\n     except Exception as e:\n         print(f\"❌ FAILED: {str(e)}\")\n         import traceback\n         traceback.print_exc()\n         return False\n \n+\n def main():\n     \"\"\"Test all SQL files.\"\"\"\n     test_files = [\n         'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train.sql',\n         'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train2.sql',\n         'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\testing.sql',\n         'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\full_sql_test.sql',\n     ]\n-    \n+\n     results = {}\n     for filepath in test_files:\n         if Path(filepath).exists():\n             results[Path(filepath).name] = test_sql_file(filepath)\n         else:\n             print(f\"\\n⚠️  File not found: {filepath}\")\n             results[Path(filepath).name] = None\n-    \n+\n     # Summary\n     print(f\"\\n{'='*70}\")\n     print(\"TEST SUMMARY\")\n     print('='*70)\n     for filename, result in results.items():\n-        status = \"✓ PASS\" if result is True else (\"⚠️  WARN\" if result is False else \"❌ MISSING\")\n+        status = \"✓ PASS\" if result is True else (\n+            \"⚠️  WARN\" if result is False else \"❌ MISSING\")\n         print(f\"{status}: {filename}\")\n-    \n+\n     passed = sum(1 for r in results.values() if r is True)\n     total = sum(1 for r in results.values() if r is not None)\n     print(f\"\\nTotal: {passed}/{total} passed\")\n \n+\n if __name__ == '__main__':\n     main()\n"
                },
                {
                    "date": 1769012590308,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,9 +6,13 @@\n \n import json\n import sys\n from pathlib import Path\n+from antlr4 import InputStream, CommonTokenStream\n+from BaseLexer import BaseLexer as MyBaseLexer\n+from SQLParser import SQLParser as MyParser\n from builders.ast_builder import AstBuilder\n+from dataclasses import asdict, is_dataclass\n \n \n def count_nulls_in_ast(node, null_fields=None):\n     \"\"\"Recursively count null values in AST, tracking which fields are null.\"\"\"\n"
                },
                {
                    "date": 1769012670107,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,30 +46,36 @@\n             sql_content = f.read()\n \n         print(f\"File size: {len(sql_content)} characters\")\n \n+        # Parse SQL into AST\n+        lexer = MyBaseLexer(InputStream(sql_content))\n+        token_stream = CommonTokenStream(lexer)\n+        token_stream.fill()\n+        parser = MyParser(token_stream)\n+        tree = parser.sqlScript()\n+        \n+        # Build AST using visitor\n         builder = AstBuilder()\n-        ast = builder.build(sql_content)\n+        ast = builder.visit(tree)\n \n         if not ast:\n             print(\"❌ FAILED: No AST generated\")\n             return False\n \n-        # Convert to JSON for analysis\n+        # Convert to dict for analysis\n+        ast_dict = to_dict(ast)\n+        json_output = json.dumps(ast_dict, indent=2, default=str)\n+        \n         if isinstance(ast, list):\n-            json_output = json.dumps([stmt.__dict__ if hasattr(\n-                stmt, '__dict__') else stmt for stmt in ast], indent=2, default=str)\n             statement_count = len(ast)\n         else:\n-            json_output = json.dumps(ast.__dict__ if hasattr(\n-                ast, '__dict__') else ast, indent=2, default=str)\n             statement_count = 1\n \n         print(f\"✓ Parsed {statement_count} statement(s)\")\n         print(f\"AST Output length: {len(json_output)} characters\")\n \n         # Count null values\n-        ast_dict = json.loads(json_output)\n         null_fields = count_nulls_in_ast(ast_dict)\n \n         # Critical fields that should not be null\n         critical_fields = {'selectList', 'expression', 'fromClause',\n@@ -80,9 +86,9 @@\n \n         if critical_nulls:\n             print(\n                 f\"⚠️  WARNING: Found nulls in critical fields: {critical_nulls}\")\n-            return False\n+            # Don't return False, some statements might not have all clauses\n         else:\n             print(\"✓ No nulls in critical fields\")\n \n         # Show first statement sample\n"
                },
                {
                    "date": 1769012698350,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,9 +52,9 @@\n         token_stream = CommonTokenStream(lexer)\n         token_stream.fill()\n         parser = MyParser(token_stream)\n         tree = parser.sqlScript()\n-        \n+\n         # Build AST using visitor\n         builder = AstBuilder()\n         ast = builder.visit(tree)\n \n@@ -64,9 +64,9 @@\n \n         # Convert to dict for analysis\n         ast_dict = to_dict(ast)\n         json_output = json.dumps(ast_dict, indent=2, default=str)\n-        \n+\n         if isinstance(ast, list):\n             statement_count = len(ast)\n         else:\n             statement_count = 1\n@@ -93,19 +93,42 @@\n \n         # Show first statement sample\n         if isinstance(ast_dict, list) and ast_dict:\n             first_stmt = ast_dict[0]\n-            print(\n-                f\"\\nFirst statement type: {first_stmt.get('__class__', 'unknown')}\")\n-            if 'selectList' in first_stmt and first_stmt['selectList']:\n-                print(f\"  - selectList items: {len(first_stmt['selectList'])}\")\n-                first_item = first_stmt['selectList'][0]\n-                print(\n-                    f\"    - First item expression: {type(first_item.get('expression'))}\")\n-                if isinstance(first_item.get('expression'), dict):\n-                    expr = first_item['expression']\n-                    print(f\"      - column_name: {expr.get('column_name')}\")\n-                    print(f\"      - table_name: {expr.get('table_name')}\")\n+            print(f\"\\nFirst statement:\")\n+            \n+            # Show class type\n+            class_name = first_stmt.get('__class__', 'unknown')\n+            print(f\"  Type: {class_name}\")\n+            \n+            # Show key fields if it's a SELECT\n+            if 'selectList' in first_stmt:\n+                select_list = first_stmt.get('selectList')\n+                if select_list:\n+                    print(f\"  selectList: {len(select_list)} items\")\n+                    first_item = select_list[0] if isinstance(select_list, list) else {}\n+                    expr = first_item.get('expression', {})\n+                    if isinstance(expr, dict) and expr:\n+                        print(f\"    - First expression type: {expr.get('__class__', 'unknown')}\")\n+                        print(f\"      column_name: {expr.get('column_name', 'N/A')}\")\n+                        print(f\"      table_name: {expr.get('table_name', 'N/A')}\")\n+            \n+            # Show FROM clause\n+            from_clause = first_stmt.get('fromClause')\n+            if from_clause:\n+                print(f\"  fromClause: Present ✓\")\n+                if isinstance(from_clause, dict):\n+                    table_source = from_clause.get('tableSource', [])\n+                    if table_source:\n+                        first_table = table_source[0] if isinstance(table_source, list) else {}\n+                        print(f\"    - Table: {first_table.get('name', 'N/A')}\")\n+            \n+            # Show WHERE clause\n+            where_clause = first_stmt.get('whereClause')\n+            if where_clause:\n+                print(f\"  whereClause: Present ✓\")\n+            else:\n+                print(f\"  whereClause: None (might be expected)\")\n \n         return True\n \n     except Exception as e:\n@@ -117,33 +140,38 @@\n \n def main():\n     \"\"\"Test all SQL files.\"\"\"\n     test_files = [\n-        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train.sql',\n-        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train2.sql',\n-        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\testing.sql',\n-        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\full_sql_test.sql',\n+        'train.sql',\n+        'train2.sql',\n+        'testing.sql',\n+        'full_sql_test.sql',\n     ]\n \n     results = {}\n-    for filepath in test_files:\n-        if Path(filepath).exists():\n-            results[Path(filepath).name] = test_sql_file(filepath)\n+    for filename in test_files:\n+        filepath = Path(filename)\n+        if filepath.exists():\n+            results[filename] = test_sql_file(str(filepath))\n         else:\n-            print(f\"\\n⚠️  File not found: {filepath}\")\n-            results[Path(filepath).name] = None\n+            print(f\"\\n⚠️  File not found: {filename}\")\n+            results[filename] = None\n \n     # Summary\n     print(f\"\\n{'='*70}\")\n     print(\"TEST SUMMARY\")\n     print('='*70)\n     for filename, result in results.items():\n-        status = \"✓ PASS\" if result is True else (\n-            \"⚠️  WARN\" if result is False else \"❌ MISSING\")\n+        if result is True:\n+            status = \"✓ PASS\"\n+        elif result is False:\n+            status = \"⚠️  ISSUES\"\n+        else:\n+            status = \"❌ MISSING\"\n         print(f\"{status}: {filename}\")\n \n     passed = sum(1 for r in results.values() if r is True)\n-    total = sum(1 for r in results.values() if r is not None)\n+    tested = sum(1 for r in results.values() if r is not None)\n     print(f\"\\nTotal: {passed}/{total} passed\")\n \n \n if __name__ == '__main__':\n"
                },
                {
                    "date": 1769012705196,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,35 +94,40 @@\n         # Show first statement sample\n         if isinstance(ast_dict, list) and ast_dict:\n             first_stmt = ast_dict[0]\n             print(f\"\\nFirst statement:\")\n-            \n+\n             # Show class type\n             class_name = first_stmt.get('__class__', 'unknown')\n             print(f\"  Type: {class_name}\")\n-            \n+\n             # Show key fields if it's a SELECT\n             if 'selectList' in first_stmt:\n                 select_list = first_stmt.get('selectList')\n                 if select_list:\n                     print(f\"  selectList: {len(select_list)} items\")\n-                    first_item = select_list[0] if isinstance(select_list, list) else {}\n+                    first_item = select_list[0] if isinstance(\n+                        select_list, list) else {}\n                     expr = first_item.get('expression', {})\n                     if isinstance(expr, dict) and expr:\n-                        print(f\"    - First expression type: {expr.get('__class__', 'unknown')}\")\n-                        print(f\"      column_name: {expr.get('column_name', 'N/A')}\")\n-                        print(f\"      table_name: {expr.get('table_name', 'N/A')}\")\n-            \n+                        print(\n+                            f\"    - First expression type: {expr.get('__class__', 'unknown')}\")\n+                        print(\n+                            f\"      column_name: {expr.get('column_name', 'N/A')}\")\n+                        print(\n+                            f\"      table_name: {expr.get('table_name', 'N/A')}\")\n+\n             # Show FROM clause\n             from_clause = first_stmt.get('fromClause')\n             if from_clause:\n                 print(f\"  fromClause: Present ✓\")\n                 if isinstance(from_clause, dict):\n                     table_source = from_clause.get('tableSource', [])\n                     if table_source:\n-                        first_table = table_source[0] if isinstance(table_source, list) else {}\n+                        first_table = table_source[0] if isinstance(\n+                            table_source, list) else {}\n                         print(f\"    - Table: {first_table.get('name', 'N/A')}\")\n-            \n+\n             # Show WHERE clause\n             where_clause = first_stmt.get('whereClause')\n             if where_clause:\n                 print(f\"  whereClause: Present ✓\")\n@@ -170,9 +175,12 @@\n         print(f\"{status}: {filename}\")\n \n     passed = sum(1 for r in results.values() if r is True)\n     tested = sum(1 for r in results.values() if r is not None)\n-    print(f\"\\nTotal: {passed}/{total} passed\")\n+    print(f\"\\nTotal: {passed}/{tested} passed\")\n \n+if __name__ == '__main__':\n+    main()\n \n+\n if __name__ == '__main__':\n     main()\n"
                },
                {
                    "date": 1769012725258,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,8 +13,18 @@\n from builders.ast_builder import AstBuilder\n from dataclasses import asdict, is_dataclass\n \n \n+def to_dict(obj):\n+    \"\"\"Convert dataclass objects to dictionaries recursively.\"\"\"\n+    if is_dataclass(obj):\n+        return {k: to_dict(v) for k, v in asdict(obj).items()}\n+    elif isinstance(obj, list):\n+        return [to_dict(item) for item in obj]\n+    else:\n+        return obj\n+\n+\n def count_nulls_in_ast(node, null_fields=None):\n     \"\"\"Recursively count null values in AST, tracking which fields are null.\"\"\"\n     if null_fields is None:\n         null_fields = {}\n@@ -177,8 +187,9 @@\n     passed = sum(1 for r in results.values() if r is True)\n     tested = sum(1 for r in results.values() if r is not None)\n     print(f\"\\nTotal: {passed}/{tested} passed\")\n \n+\n if __name__ == '__main__':\n     main()\n \n \n"
                },
                {
                    "date": 1769013019692,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,20 +1,18 @@\n #!/usr/bin/env python3\n \"\"\"\n-Comprehensive test script to validate AST building for all SQL test files.\n-Tests: train.sql, train2.sql, testing.sql, full_sql_test.sql\n+Comprehensive test to analyze ALL null values in AST across all SQL test files.\n+This will help identify if nulls are expected or indicate missing data.\n \"\"\"\n \n import json\n-import sys\n from pathlib import Path\n from antlr4 import InputStream, CommonTokenStream\n from BaseLexer import BaseLexer as MyBaseLexer\n from SQLParser import SQLParser as MyParser\n from builders.ast_builder import AstBuilder\n from dataclasses import asdict, is_dataclass\n \n-\n def to_dict(obj):\n     \"\"\"Convert dataclass objects to dictionaries recursively.\"\"\"\n     if is_dataclass(obj):\n         return {k: to_dict(v) for k, v in asdict(obj).items()}\n@@ -22,28 +20,64 @@\n         return [to_dict(item) for item in obj]\n     else:\n         return obj\n \n-\n-def count_nulls_in_ast(node, null_fields=None):\n-    \"\"\"Recursively count null values in AST, tracking which fields are null.\"\"\"\n-    if null_fields is None:\n-        null_fields = {}\n-\n+def collect_nulls_detailed(node, path=\"\", null_map=None):\n+    \"\"\"Recursively collect ALL null values with their paths.\"\"\"\n+    if null_map is None:\n+        null_map = {}\n+    \n     if node is None:\n-        return null_fields\n-\n+        return null_map\n+    \n     if isinstance(node, dict):\n         for key, value in node.items():\n+            current_path = f\"{path}.{key}\" if path else key\n             if value is None:\n-                null_fields[key] = null_fields.get(key, 0) + 1\n+                if current_path not in null_map:\n+                    null_map[current_path] = 0\n+                null_map[current_path] += 1\n             elif isinstance(value, (dict, list)):\n-                count_nulls_in_ast(value, null_fields)\n+                collect_nulls_detailed(value, current_path, null_map)\n     elif isinstance(node, list):\n-        for item in node:\n-            count_nulls_in_ast(item, null_fields)\n+        for idx, item in enumerate(node):\n+            current_path = f\"{path}[{idx}]\"\n+            collect_nulls_detailed(item, current_path, null_map)\n+    \n+    return null_map\n \n-    return null_fields\n+def count_statements_with_nulls(ast):\n+    \"\"\"Count how many statements have null values.\"\"\"\n+    if not isinstance(ast, list):\n+        ast = [ast]\n+    \n+    stats = {\n+        'total_statements': len(ast),\n+        'statements_with_nulls': 0,\n+        'null_counts_by_field': {},\n+        'statements_details': []\n+    }\n+    \n+    for stmt_idx, stmt in enumerate(ast):\n+        stmt_dict = to_dict(stmt)\n+        nulls = collect_nulls_detailed(stmt_dict)\n+        \n+        if nulls:\n+            stats['statements_with_nulls'] += 1\n+            stmt_info = {\n+                'index': stmt_idx,\n+                'type': stmt_dict.get('__class__', 'unknown'),\n+                'null_count': sum(nulls.values()),\n+                'null_fields': nulls\n+            }\n+            stats['statements_details'].append(stmt_info)\n+            \n+            for field, count in nulls.items():\n+                if field not in stats['null_counts_by_field']:\n+                    stats['null_counts_by_field'][field] = 0\n+                stats['null_counts_by_field'][field] += count\n+    \n+    return stats\n \n \n def test_sql_file(filepath):\n     \"\"\"Test a single SQL file and report results.\"\"\"\n"
                },
                {
                    "date": 1769013051268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,8 +11,9 @@\n from SQLParser import SQLParser as MyParser\n from builders.ast_builder import AstBuilder\n from dataclasses import asdict, is_dataclass\n \n+\n def to_dict(obj):\n     \"\"\"Convert dataclass objects to dictionaries recursively.\"\"\"\n     if is_dataclass(obj):\n         return {k: to_dict(v) for k, v in asdict(obj).items()}\n@@ -20,16 +21,17 @@\n         return [to_dict(item) for item in obj]\n     else:\n         return obj\n \n+\n def collect_nulls_detailed(node, path=\"\", null_map=None):\n     \"\"\"Recursively collect ALL null values with their paths.\"\"\"\n     if null_map is None:\n         null_map = {}\n-    \n+\n     if node is None:\n         return null_map\n-    \n+\n     if isinstance(node, dict):\n         for key, value in node.items():\n             current_path = f\"{path}.{key}\" if path else key\n             if value is None:\n@@ -41,27 +43,28 @@\n     elif isinstance(node, list):\n         for idx, item in enumerate(node):\n             current_path = f\"{path}[{idx}]\"\n             collect_nulls_detailed(item, current_path, null_map)\n-    \n+\n     return null_map\n \n+\n def count_statements_with_nulls(ast):\n     \"\"\"Count how many statements have null values.\"\"\"\n     if not isinstance(ast, list):\n         ast = [ast]\n-    \n+\n     stats = {\n         'total_statements': len(ast),\n         'statements_with_nulls': 0,\n         'null_counts_by_field': {},\n         'statements_details': []\n     }\n-    \n+\n     for stmt_idx, stmt in enumerate(ast):\n         stmt_dict = to_dict(stmt)\n         nulls = collect_nulls_detailed(stmt_dict)\n-        \n+\n         if nulls:\n             stats['statements_with_nulls'] += 1\n             stmt_info = {\n                 'index': stmt_idx,\n@@ -69,123 +72,77 @@\n                 'null_count': sum(nulls.values()),\n                 'null_fields': nulls\n             }\n             stats['statements_details'].append(stmt_info)\n-            \n+\n             for field, count in nulls.items():\n                 if field not in stats['null_counts_by_field']:\n                     stats['null_counts_by_field'][field] = 0\n                 stats['null_counts_by_field'][field] += count\n-    \n+\n     return stats\n \n \n def test_sql_file(filepath):\n-    \"\"\"Test a single SQL file and report results.\"\"\"\n-    print(f\"\\n{'='*70}\")\n-    print(f\"Testing: {Path(filepath).name}\")\n-    print('='*70)\n-\n+    \"\"\"Test a single SQL file and analyze nulls.\"\"\"\n+    print(f\"\\n{'='*80}\")\n+    print(f\"FILE: {Path(filepath).name}\")\n+    print('='*80)\n+    \n     try:\n         with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n             sql_content = f.read()\n-\n-        print(f\"File size: {len(sql_content)} characters\")\n-\n-        # Parse SQL into AST\n+        \n+        print(f\"Size: {len(sql_content)} characters\")\n+        \n+        # Parse\n         lexer = MyBaseLexer(InputStream(sql_content))\n         token_stream = CommonTokenStream(lexer)\n         token_stream.fill()\n         parser = MyParser(token_stream)\n         tree = parser.sqlScript()\n-\n-        # Build AST using visitor\n+        \n+        # Build AST\n         builder = AstBuilder()\n         ast = builder.visit(tree)\n-\n+        \n         if not ast:\n-            print(\"❌ FAILED: No AST generated\")\n-            return False\n-\n-        # Convert to dict for analysis\n-        ast_dict = to_dict(ast)\n-        json_output = json.dumps(ast_dict, indent=2, default=str)\n-\n-        if isinstance(ast, list):\n-            statement_count = len(ast)\n+            print(\"ERROR: No AST generated\")\n+            return None\n+        \n+        # Analyze\n+        stats = count_statements_with_nulls(ast)\n+        \n+        print(f\"\\n✓ Parsed {stats['total_statements']} statement(s)\")\n+        print(f\"⚠️  {stats['statements_with_nulls']} statement(s) with null values\")\n+        \n+        print(f\"\\n--- NULL VALUES BY FIELD ---\")\n+        if stats['null_counts_by_field']:\n+            for field, count in sorted(stats['null_counts_by_field'].items(), key=lambda x: x[1], reverse=True):\n+                print(f\"  {field}: {count} null(s)\")\n         else:\n-            statement_count = 1\n-\n-        print(f\"✓ Parsed {statement_count} statement(s)\")\n-        print(f\"AST Output length: {len(json_output)} characters\")\n-\n-        # Count null values\n-        null_fields = count_nulls_in_ast(ast_dict)\n-\n-        # Critical fields that should not be null\n-        critical_fields = {'selectList', 'expression', 'fromClause',\n-                           'whereClause', 'orderByClause', 'column_name', 'tableName'}\n-\n-        critical_nulls = {k: v for k,\n-                          v in null_fields.items() if k in critical_fields}\n-\n-        if critical_nulls:\n-            print(\n-                f\"⚠️  WARNING: Found nulls in critical fields: {critical_nulls}\")\n-            # Don't return False, some statements might not have all clauses\n-        else:\n-            print(\"✓ No nulls in critical fields\")\n-\n-        # Show first statement sample\n-        if isinstance(ast_dict, list) and ast_dict:\n-            first_stmt = ast_dict[0]\n-            print(f\"\\nFirst statement:\")\n-\n-            # Show class type\n-            class_name = first_stmt.get('__class__', 'unknown')\n-            print(f\"  Type: {class_name}\")\n-\n-            # Show key fields if it's a SELECT\n-            if 'selectList' in first_stmt:\n-                select_list = first_stmt.get('selectList')\n-                if select_list:\n-                    print(f\"  selectList: {len(select_list)} items\")\n-                    first_item = select_list[0] if isinstance(\n-                        select_list, list) else {}\n-                    expr = first_item.get('expression', {})\n-                    if isinstance(expr, dict) and expr:\n-                        print(\n-                            f\"    - First expression type: {expr.get('__class__', 'unknown')}\")\n-                        print(\n-                            f\"      column_name: {expr.get('column_name', 'N/A')}\")\n-                        print(\n-                            f\"      table_name: {expr.get('table_name', 'N/A')}\")\n-\n-            # Show FROM clause\n-            from_clause = first_stmt.get('fromClause')\n-            if from_clause:\n-                print(f\"  fromClause: Present ✓\")\n-                if isinstance(from_clause, dict):\n-                    table_source = from_clause.get('tableSource', [])\n-                    if table_source:\n-                        first_table = table_source[0] if isinstance(\n-                            table_source, list) else {}\n-                        print(f\"    - Table: {first_table.get('name', 'N/A')}\")\n-\n-            # Show WHERE clause\n-            where_clause = first_stmt.get('whereClause')\n-            if where_clause:\n-                print(f\"  whereClause: Present ✓\")\n-            else:\n-                print(f\"  whereClause: None (might be expected)\")\n-\n-        return True\n-\n+            print(\"  (No nulls found)\")\n+        \n+        print(f\"\\n--- STATEMENT DETAILS ---\")\n+        for stmt_info in stats['statements_details'][:5]:  # Show first 5\n+            print(f\"\\n  Statement {stmt_info['index']} ({stmt_info['type']}):\")\n+            print(f\"    Total nulls: {stmt_info['null_count']}\")\n+            print(f\"    Null fields:\")\n+            for field in list(stmt_info['null_fields'].keys())[:10]:  # Show first 10 fields\n+                print(f\"      - {field}\")\n+            if len(stmt_info['null_fields']) > 10:\n+                print(f\"      ... and {len(stmt_info['null_fields']) - 10} more\")\n+        \n+        if len(stats['statements_details']) > 5:\n+            print(f\"\\n  ... and {len(stats['statements_details']) - 5} more statements with nulls\")\n+        \n+        return stats\n+    \n     except Exception as e:\n-        print(f\"❌ FAILED: {str(e)}\")\n+        print(f\"ERROR: {str(e)}\")\n         import traceback\n         traceback.print_exc()\n-        return False\n+        return None\n \n \n def main():\n     \"\"\"Test all SQL files.\"\"\"\n"
                },
                {
                    "date": 1769013075235,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,103 +86,134 @@\n     \"\"\"Test a single SQL file and analyze nulls.\"\"\"\n     print(f\"\\n{'='*80}\")\n     print(f\"FILE: {Path(filepath).name}\")\n     print('='*80)\n-    \n+\n     try:\n         with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n             sql_content = f.read()\n-        \n+\n         print(f\"Size: {len(sql_content)} characters\")\n-        \n+\n         # Parse\n         lexer = MyBaseLexer(InputStream(sql_content))\n         token_stream = CommonTokenStream(lexer)\n         token_stream.fill()\n         parser = MyParser(token_stream)\n         tree = parser.sqlScript()\n-        \n+\n         # Build AST\n         builder = AstBuilder()\n         ast = builder.visit(tree)\n-        \n+\n         if not ast:\n             print(\"ERROR: No AST generated\")\n             return None\n-        \n+\n         # Analyze\n         stats = count_statements_with_nulls(ast)\n-        \n+\n         print(f\"\\n✓ Parsed {stats['total_statements']} statement(s)\")\n-        print(f\"⚠️  {stats['statements_with_nulls']} statement(s) with null values\")\n-        \n+        print(\n+            f\"⚠️  {stats['statements_with_nulls']} statement(s) with null values\")\n+\n         print(f\"\\n--- NULL VALUES BY FIELD ---\")\n         if stats['null_counts_by_field']:\n             for field, count in sorted(stats['null_counts_by_field'].items(), key=lambda x: x[1], reverse=True):\n                 print(f\"  {field}: {count} null(s)\")\n         else:\n             print(\"  (No nulls found)\")\n-        \n+\n         print(f\"\\n--- STATEMENT DETAILS ---\")\n         for stmt_info in stats['statements_details'][:5]:  # Show first 5\n             print(f\"\\n  Statement {stmt_info['index']} ({stmt_info['type']}):\")\n             print(f\"    Total nulls: {stmt_info['null_count']}\")\n             print(f\"    Null fields:\")\n-            for field in list(stmt_info['null_fields'].keys())[:10]:  # Show first 10 fields\n+            # Show first 10 fields\n+            for field in list(stmt_info['null_fields'].keys())[:10]:\n                 print(f\"      - {field}\")\n             if len(stmt_info['null_fields']) > 10:\n-                print(f\"      ... and {len(stmt_info['null_fields']) - 10} more\")\n-        \n+                print(\n+                    f\"      ... and {len(stmt_info['null_fields']) - 10} more\")\n+\n         if len(stats['statements_details']) > 5:\n-            print(f\"\\n  ... and {len(stats['statements_details']) - 5} more statements with nulls\")\n-        \n+            print(\n+                f\"\\n  ... and {len(stats['statements_details']) - 5} more statements with nulls\")\n+\n         return stats\n-    \n+\n     except Exception as e:\n         print(f\"ERROR: {str(e)}\")\n         import traceback\n         traceback.print_exc()\n         return None\n \n \n def main():\n-    \"\"\"Test all SQL files.\"\"\"\n+    \"\"\"Test all SQL files and provide comprehensive null analysis.\"\"\"\n     test_files = [\n         'train.sql',\n         'train2.sql',\n         'testing.sql',\n         'full_sql_test.sql',\n     ]\n-\n-    results = {}\n+    \n+    all_results = {}\n+    total_stats = {\n+        'total_files': 0,\n+        'total_statements': 0,\n+        'total_statements_with_nulls': 0,\n+        'overall_null_counts': {}\n+    }\n+    \n     for filename in test_files:\n         filepath = Path(filename)\n         if filepath.exists():\n-            results[filename] = test_sql_file(str(filepath))\n+            result = test_sql_file(str(filepath))\n+            if result:\n+                all_results[filename] = result\n+                total_stats['total_files'] += 1\n+                total_stats['total_statements'] += result['total_statements']\n+                total_stats['total_statements_with_nulls'] += result['statements_with_nulls']\n+                for field, count in result['null_counts_by_field'].items():\n+                    if field not in total_stats['overall_null_counts']:\n+                        total_stats['overall_null_counts'][field] = 0\n+                    total_stats['overall_null_counts'][field] += count\n         else:\n             print(f\"\\n⚠️  File not found: {filename}\")\n-            results[filename] = None\n+    \n+    # Print summary\n+    print(f\"\\n\\n{'='*80}\")\n+    print(\"COMPREHENSIVE TEST SUMMARY\")\n+    print('='*80)\n+    \n+    print(f\"\\nFiles tested: {total_stats['total_files']}\")\n+    print(f\"Total statements: {total_stats['total_statements']}\")\n+    print(f\"Statements with nulls: {total_stats['total_statements_with_nulls']}\")\n+    print(f\"Percentage with nulls: {(total_stats['total_statements_with_nulls'] / total_stats['total_statements'] * 100):.1f}%\")\n+    \n+    print(f\"\\n--- ALL NULL FIELDS (ACROSS ALL FILES) ---\")\n+    if total_stats['overall_null_counts']:\n+        print(f\"Total unique null field paths: {len(total_stats['overall_null_counts'])}\")\n+        print(f\"\\nNull count by field (top 20):\")\n+        for field, count in sorted(total_stats['overall_null_counts'].items(), key=lambda x: x[1], reverse=True)[:20]:\n+            print(f\"  {field}: {count}\")\n+    else:\n+        print(\"  (No nulls found)\")\n+    \n+    print(f\"\\n--- BREAKDOWN BY FILE ---\")\n+    for filename, stats in all_results.items():\n+        pct = (stats['statements_with_nulls'] / stats['total_statements'] * 100) if stats['total_statements'] > 0 else 0\n+        print(f\"\\n{filename}:\")\n+        print(f\"  Statements: {stats['total_statements']}\")\n+        print(f\"  With nulls: {stats['statements_with_nulls']} ({pct:.1f}%)\")\n+        print(f\"  Total nulls: {sum(stats['null_counts_by_field'].values())}\")\n+        \n+        # Show top 5 null fields for this file\n+        top_nulls = sorted(stats['null_counts_by_field'].items(), key=lambda x: x[1], reverse=True)[:5]\n+        if top_nulls:\n+            print(f\"  Top null fields:\")\n+            for field, count in top_nulls:\n+                print(f\"    - {field}: {count}\")\n \n-    # Summary\n-    print(f\"\\n{'='*70}\")\n-    print(\"TEST SUMMARY\")\n-    print('='*70)\n-    for filename, result in results.items():\n-        if result is True:\n-            status = \"✓ PASS\"\n-        elif result is False:\n-            status = \"⚠️  ISSUES\"\n-        else:\n-            status = \"❌ MISSING\"\n-        print(f\"{status}: {filename}\")\n-\n-    passed = sum(1 for r in results.values() if r is True)\n-    tested = sum(1 for r in results.values() if r is not None)\n-    print(f\"\\nTotal: {passed}/{tested} passed\")\n-\n-\n if __name__ == '__main__':\n     main()\n-\n-\n-if __name__ == '__main__':\n-    main()\n"
                },
                {
                    "date": 1769013172334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,16 +4,22 @@\n This will help identify if nulls are expected or indicate missing data.\n \"\"\"\n \n import json\n+import sys\n from pathlib import Path\n from antlr4 import InputStream, CommonTokenStream\n from BaseLexer import BaseLexer as MyBaseLexer\n from SQLParser import SQLParser as MyParser\n from builders.ast_builder import AstBuilder\n from dataclasses import asdict, is_dataclass\n \n+# Fix encoding on Windows\n+if sys.stdout.encoding != 'utf-8':\n+    import io\n+    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')\n \n+\n def to_dict(obj):\n     \"\"\"Convert dataclass objects to dictionaries recursively.\"\"\"\n     if is_dataclass(obj):\n         return {k: to_dict(v) for k, v in asdict(obj).items()}\n@@ -155,17 +161,17 @@\n         'train2.sql',\n         'testing.sql',\n         'full_sql_test.sql',\n     ]\n-    \n+\n     all_results = {}\n     total_stats = {\n         'total_files': 0,\n         'total_statements': 0,\n         'total_statements_with_nulls': 0,\n         'overall_null_counts': {}\n     }\n-    \n+\n     for filename in test_files:\n         filepath = Path(filename)\n         if filepath.exists():\n             result = test_sql_file(str(filepath))\n@@ -179,41 +185,47 @@\n                         total_stats['overall_null_counts'][field] = 0\n                     total_stats['overall_null_counts'][field] += count\n         else:\n             print(f\"\\n⚠️  File not found: {filename}\")\n-    \n+\n     # Print summary\n     print(f\"\\n\\n{'='*80}\")\n     print(\"COMPREHENSIVE TEST SUMMARY\")\n     print('='*80)\n-    \n+\n     print(f\"\\nFiles tested: {total_stats['total_files']}\")\n     print(f\"Total statements: {total_stats['total_statements']}\")\n-    print(f\"Statements with nulls: {total_stats['total_statements_with_nulls']}\")\n-    print(f\"Percentage with nulls: {(total_stats['total_statements_with_nulls'] / total_stats['total_statements'] * 100):.1f}%\")\n-    \n+    print(\n+        f\"Statements with nulls: {total_stats['total_statements_with_nulls']}\")\n+    print(\n+        f\"Percentage with nulls: {(total_stats['total_statements_with_nulls'] / total_stats['total_statements'] * 100):.1f}%\")\n+\n     print(f\"\\n--- ALL NULL FIELDS (ACROSS ALL FILES) ---\")\n     if total_stats['overall_null_counts']:\n-        print(f\"Total unique null field paths: {len(total_stats['overall_null_counts'])}\")\n+        print(\n+            f\"Total unique null field paths: {len(total_stats['overall_null_counts'])}\")\n         print(f\"\\nNull count by field (top 20):\")\n         for field, count in sorted(total_stats['overall_null_counts'].items(), key=lambda x: x[1], reverse=True)[:20]:\n             print(f\"  {field}: {count}\")\n     else:\n         print(\"  (No nulls found)\")\n-    \n+\n     print(f\"\\n--- BREAKDOWN BY FILE ---\")\n     for filename, stats in all_results.items():\n-        pct = (stats['statements_with_nulls'] / stats['total_statements'] * 100) if stats['total_statements'] > 0 else 0\n+        pct = (stats['statements_with_nulls'] / stats['total_statements']\n+               * 100) if stats['total_statements'] > 0 else 0\n         print(f\"\\n{filename}:\")\n         print(f\"  Statements: {stats['total_statements']}\")\n         print(f\"  With nulls: {stats['statements_with_nulls']} ({pct:.1f}%)\")\n         print(f\"  Total nulls: {sum(stats['null_counts_by_field'].values())}\")\n-        \n+\n         # Show top 5 null fields for this file\n-        top_nulls = sorted(stats['null_counts_by_field'].items(), key=lambda x: x[1], reverse=True)[:5]\n+        top_nulls = sorted(stats['null_counts_by_field'].items(\n+        ), key=lambda x: x[1], reverse=True)[:5]\n         if top_nulls:\n             print(f\"  Top null fields:\")\n             for field, count in top_nulls:\n                 print(f\"    - {field}: {count}\")\n \n+\n if __name__ == '__main__':\n     main()\n"
                },
                {
                    "date": 1769013223468,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,9 +15,10 @@\n \n # Fix encoding on Windows\n if sys.stdout.encoding != 'utf-8':\n     import io\n-    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')\n+    sys.stdout = io.TextIOWrapper(\n+        sys.stdout.buffer, encoding='utf-8', errors='replace')\n \n \n def to_dict(obj):\n     \"\"\"Convert dataclass objects to dictionaries recursively.\"\"\"\n@@ -195,10 +196,13 @@\n     print(f\"\\nFiles tested: {total_stats['total_files']}\")\n     print(f\"Total statements: {total_stats['total_statements']}\")\n     print(\n         f\"Statements with nulls: {total_stats['total_statements_with_nulls']}\")\n-    print(\n-        f\"Percentage with nulls: {(total_stats['total_statements_with_nulls'] / total_stats['total_statements'] * 100):.1f}%\")\n+    if total_stats['total_statements'] > 0:\n+        pct = (total_stats['total_statements_with_nulls'] / total_stats['total_statements'] * 100)\n+        print(f\"Percentage with nulls: {pct:.1f}%\")\n+    else:\n+        print(\"Percentage with nulls: N/A\")\n \n     print(f\"\\n--- ALL NULL FIELDS (ACROSS ALL FILES) ---\")\n     if total_stats['overall_null_counts']:\n         print(\n"
                }
            ],
            "date": 1769012520768,
            "name": "Commit-0",
            "content": "#!/usr/bin/env python3\n\"\"\"\nComprehensive test script to validate AST building for all SQL test files.\nTests: train.sql, train2.sql, testing.sql, full_sql_test.sql\n\"\"\"\n\nimport json\nfrom pathlib import Path\nfrom Ast.ast_builder import AstBuilder\nfrom utils.logger import Logger\n\ndef count_nulls_in_ast(node, null_fields=None):\n    \"\"\"Recursively count null values in AST, tracking which fields are null.\"\"\"\n    if null_fields is None:\n        null_fields = {}\n    \n    if node is None:\n        return null_fields\n    \n    if isinstance(node, dict):\n        for key, value in node.items():\n            if value is None:\n                null_fields[key] = null_fields.get(key, 0) + 1\n            elif isinstance(value, (dict, list)):\n                count_nulls_in_ast(value, null_fields)\n    elif isinstance(node, list):\n        for item in node:\n            count_nulls_in_ast(item, null_fields)\n    \n    return null_fields\n\ndef test_sql_file(filepath):\n    \"\"\"Test a single SQL file and report results.\"\"\"\n    print(f\"\\n{'='*70}\")\n    print(f\"Testing: {Path(filepath).name}\")\n    print('='*70)\n    \n    try:\n        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n            sql_content = f.read()\n        \n        print(f\"File size: {len(sql_content)} characters\")\n        \n        builder = AstBuilder()\n        ast = builder.build(sql_content)\n        \n        if not ast:\n            print(\"❌ FAILED: No AST generated\")\n            return False\n        \n        # Convert to JSON for analysis\n        if isinstance(ast, list):\n            json_output = json.dumps([stmt.__dict__ if hasattr(stmt, '__dict__') else stmt for stmt in ast], indent=2, default=str)\n            statement_count = len(ast)\n        else:\n            json_output = json.dumps(ast.__dict__ if hasattr(ast, '__dict__') else ast, indent=2, default=str)\n            statement_count = 1\n        \n        print(f\"✓ Parsed {statement_count} statement(s)\")\n        print(f\"AST Output length: {len(json_output)} characters\")\n        \n        # Count null values\n        ast_dict = json.loads(json_output)\n        null_fields = count_nulls_in_ast(ast_dict)\n        \n        # Critical fields that should not be null\n        critical_fields = {'selectList', 'expression', 'fromClause', 'whereClause', 'orderByClause', 'column_name', 'tableName'}\n        \n        critical_nulls = {k: v for k, v in null_fields.items() if k in critical_fields}\n        \n        if critical_nulls:\n            print(f\"⚠️  WARNING: Found nulls in critical fields: {critical_nulls}\")\n            return False\n        else:\n            print(\"✓ No nulls in critical fields\")\n        \n        # Show first statement sample\n        if isinstance(ast_dict, list) and ast_dict:\n            first_stmt = ast_dict[0]\n            print(f\"\\nFirst statement type: {first_stmt.get('__class__', 'unknown')}\")\n            if 'selectList' in first_stmt and first_stmt['selectList']:\n                print(f\"  - selectList items: {len(first_stmt['selectList'])}\")\n                first_item = first_stmt['selectList'][0]\n                print(f\"    - First item expression: {type(first_item.get('expression'))}\")\n                if isinstance(first_item.get('expression'), dict):\n                    expr = first_item['expression']\n                    print(f\"      - column_name: {expr.get('column_name')}\")\n                    print(f\"      - table_name: {expr.get('table_name')}\")\n        \n        return True\n    \n    except Exception as e:\n        print(f\"❌ FAILED: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return False\n\ndef main():\n    \"\"\"Test all SQL files.\"\"\"\n    test_files = [\n        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train.sql',\n        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\train2.sql',\n        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\testing.sql',\n        'c:\\\\Users\\\\LEGION\\\\Desktop\\\\Compiler\\\\full_sql_test.sql',\n    ]\n    \n    results = {}\n    for filepath in test_files:\n        if Path(filepath).exists():\n            results[Path(filepath).name] = test_sql_file(filepath)\n        else:\n            print(f\"\\n⚠️  File not found: {filepath}\")\n            results[Path(filepath).name] = None\n    \n    # Summary\n    print(f\"\\n{'='*70}\")\n    print(\"TEST SUMMARY\")\n    print('='*70)\n    for filename, result in results.items():\n        status = \"✓ PASS\" if result is True else (\"⚠️  WARN\" if result is False else \"❌ MISSING\")\n        print(f\"{status}: {filename}\")\n    \n    passed = sum(1 for r in results.values() if r is True)\n    total = sum(1 for r in results.values() if r is not None)\n    print(f\"\\nTotal: {passed}/{total} passed\")\n\nif __name__ == '__main__':\n    main()\n"
        }
    ]
}